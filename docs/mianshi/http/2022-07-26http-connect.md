---
sidebar_position: 17
title: 前端基础-http不同版本对比 ⚡️
---

## HTTP/1.x 的连接管理

<img src="http://t-blog-images.aijs.top/img/20220726221631.png" style={{maxWidth:450}}/>

### 短连接

1. HTTP/1.0 默认是短连接(`冷连接`),每一个 HTTP 请求都由它自己独立的连接完成,
2. TCP 协议握手耗费时间,TCP 可以保持更多的`热连接`来适应负载

:::details 查看更多
HTTP 最早期的模型，也是 HTTP/1.0 的默认模型，是短连接。每一个 HTTP 请求都由它自己独立的连接完成；这意味着发起每一个 HTTP 请求之前都会有一次 TCP 握手，而且是连续不断的。

TCP 协议握手本身就是耗费时间的，所以 TCP 可以保持更多的热连接来适应负载。短连接破坏了 TCP 具备的能力，新的`冷连接`降低了其性能。

这是 HTTP/1.0 的默认模型 (如果没有指定 Connection 协议头，或者是值被设置为 close)。而在 HTTP/1.1 中，只有当 Connection 被设置为 close 时才会用到这个模型。
:::

:::tip
<span style={{color: 'red'}}>除非是要兼容一个非常古老的，不支持长连接的系统，没有一个令人信服的理由继续使用这个模型。</span>
:::

### 长连接

**优点：**

解决`短连接`的两个比较大的问题：

1. 创建新连接耗费的时间尤为明显，
2. TCP 连接的性能只有在该连接被使用一段时间后 (`热连接`) 才能得到改善。

**缺点**

1. 空闲状态，它还是会消耗服务器资源，
2. 在重负载时，还有可能遭受 `DoS attacks` 攻击。

:::details 查看更多
为了缓解这些问题，长连接 的概念便被设计出来了，甚至在 HTTP/1.1 之前。或者这被称之为一个 keep-alive 连接。

**优点**

一个长连接会保持一段时间，重复用于发送一系列请求，节省了新建 TCP 连接握手的时间，还可以利用 TCP 的性能增强能力。当然这个连接也不会一直保留着：<span style={{color: 'red'}}>连接在空闲一段时间后会被关闭</span> (服务器可以使用 Keep-Alive 协议头来指定一个最小的连接保持时间)。

**缺点**

长连接也还是有缺点的；就算是在空闲状态，它还是会消耗服务器资源，而且在重负载时，还有可能遭受 DoS attacks 攻击。这种场景下，可以使用非长连接，即尽快关闭那些空闲的连接，也能对性能有所提升。

HTTP/1.0 里默认并不使用长连接。把 Connection 设置成 close 以外的其它参数都可以让其保持长连接，通常会设置为 retry-after。(TODO:没懂)

:::

:::warning

在 HTTP/1.1 里，默认就是长连接的，协议头都不用再去声明它 (但我们还是会把它加上，万一某个时候因为某种原因要退回到 HTTP/1.0 呢)

:::

### 流水线

:::tip
流水线已经被更好的算法给代替，如 multiplexing 多路复用，已经用在 HTTP/2
:::

1. 同一条长连接上发出连续的请求，不用等待应答返回
2. 打包成消息包提升性能
3. 幂等请求支持流水线
4. 浏览器默认关闭

:::details 查看更多
默认情况下，HTTP 请求是按顺序发出的。下一个请求只有在当前请求收到应答过后才会被发出。由于会受到网络延迟和带宽的限制，在下一个请求被发送到服务器之前，可能需要等待很长时间。

`流水线`是 在同一条长连接上发出连续的请求，而不用等待应答返回。这样可以避免连接延迟 。

**打包成消息包提升性能**

理论上讲，性能还会因为两个 HTTP 请求有可能被打包到一个 TCP 消息包中而得到提升。就算 HTTP 请求不断的继续，尺寸会增加，但设置 TCP 的 MSS(Maximum Segment Size) 选项，仍然足够包含一系列简单的请求。

**幂等 请求支持流水线**
并不是所有类型的 HTTP 请求都能用到流水线：只有 `idempotent(幂等)` 方式，比如 `GET、HEAD、PUT 和 DELETE 能够被安全的重试`：`如果有故障发生时，流水线的内容要能被轻易的重试`。

**浏览器默认关闭**
今天，所有遵循 HTTP/1.1 的代理和服务器都应该支持流水线，虽然实际情况中还是有很多限制：一个很重要的原因是，目前没有现代浏览器默认启用这个特性。
:::

### 域名分片

:::danger
除非你有紧急而迫切的需求，不要使用这一过时的技术，升级到 HTTP/2 就好了。在 HTTP/2 里，做域名分片就没必要了：HTTP/2 的连接可以很好的处理并发的无优先级的请求。域名分片甚至会影响性能。大多数 HTTP/2 的实现还会使用一种称作连接凝聚的技术去尝试合并被分片的域名。
:::

1. `作为 HTTP/1.x 的连接，请求是序列化的，哪怕本来是无序的，在没有足够庞大可用的带宽时，也无从优化。`
2. `一个解决方案是，浏览器为每个域名建立多个连接，以实现并发请求。`
3. `如果服务器端想要更快速的响应网站或应用程序的应答，它可以迫使客户端建立更多的连接。`

曾经默认的连接数量为 2 到 3 个，现在比较常用的并发连接数已经增加到 6 条。<span style={{color: 'red'}}>如果尝试大于这个数字，就有触发服务器 DoS 保护的风险</span>。

例如，不要在同一个域名下获取所有资源，假设有个域名是 `www.example.com`，我们可以把它拆分成好几个域名：`www1.example.com`、`www2.example.com`、`www3.example.com`。所有这些域名都指向同一台服务器，浏览器会同时为每个域名建立 6 条连接 (在我们这个例子中，连接数会达到 18 条)。这一技术被称作`域名分片`。

<img src="http://t-blog-images.aijs.top/img/202207271036850.webp" />

## HTTP/2

<a href="https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Basics_of_HTTP/Evolution_of_HTTP#http2_-_%E4%B8%BA%E4%BA%86%E6%9B%B4%E4%BC%98%E5%BC%82%E7%9A%84%E8%A1%A8%E7%8E%B0" target="_blank" >见</a>

### 二进制分帧

1. `帧`：HTTP/2 数据通信的最⼩单位
2. `消息`：指 HTTP/2 中逻辑上的 HTTP 消息。例如: 请求和响应等，消息由⼀个或多个帧 组成。
3. `流`：存在于连接中的⼀个虚拟通道。流可以承载双向消息，每个流都有⼀个唯⼀的整数 ID
4. `采⽤⼆进制格式传输数据`，`⽽⾮ HTTP 1.x 的⽂本格式`，`⼆进制协议解析起来更⾼效`。

### 头部压缩

**压缩的原因**
HTTP/1.x 会在请求和响应中中重复地携带不常改变的、冗⻓的头部数据，给⽹络带来额外的负担。

**压缩的原理**

1. HTTP/2 在客户端和服务器端使⽤`“⾸部表”来跟踪和存储之前发送的键－值对`，
2. 对于相同的数据，`不再通过每次请求和响应发送`
3. ⾸部表在 HTTP/2 的连接存续期内始终存在，`由客户端和服务器共同渐进地更新`;
4. 每个新的⾸部键－值对要么被追加到当前表的末尾，要么替换表中之前的值。
5. 你可以理解为只发送差异数据，⽽不是全部发送，从⽽减少头部的信息量

<img src="http://t-blog-images.aijs.top/img/202207271040589.webp" />

### 服务器推送

1. 服务端可以在发送⻚⾯ HTML 时主动推送其它资源，⽽不⽤等到浏览器解析到相应位置，发起请求再响应。例如服务端 可以主动把 JS 和 CSS ⽂件推送给客户端，⽽不需要客户端解析 HTML 时再发送这些请求。
2. 服务端可以主动推送，客户端也有权利选择是否接收。
3. 如果服务端推送的资源已经被浏览器缓存过，浏览器可以通过发 送 `RST_STREAM` 帧来拒收。
4. 主动推送也遵守同源策略，服务器不会随便推送第三⽅资源给客户端

### 多路复用

**出现的背景**

HTTP 1.x 中，如果想并发多个请求，必须使⽤多个 TCP 链接，且浏览器为了控制资源，还会对单个域名有 6-8 个的 TCP 链接请求限制。

**如何解决**

1. `同域名下所有通信都在单个连接上完成`。
2. `单个连接可以承载任意数量的双向数据流`。
3. 数据流以消息的形式发送，⽽消息⼜由⼀个或多个帧组成，多个帧之间可以`乱序发送`，因为`根据帧⾸部的流标识可以重新组装`

## HTTP/3

`HTTP/3`是第三个主要版本的 HTTP 协议。与其前任 HTTP/1.1 和 HTTP/2 不同，在 HTTP/3 中，`将弃用TCP协议，改为使用基于UDP协议的QUIC协议实现`。

**出现的背景**

此变化主要为了解决 HTTP/2 中存在的`队头阻塞`问题。由于 HTTP/2 在单个 TCP 连接上使用了`多路复用`，受到 TCP`拥塞控制`的影响，少量的丢包就可能导致整个 TCP 连接上的所有流被阻塞。

`QUIC（快速UDP网络连接）`是一种实验性的网络传输协议，由 Google 开发，该协议旨在使网页传输更快。在 2018 年 10 月 28 日的邮件列表讨论中，互联网工程任务组（IETF） HTTP 和 QUIC 工作组主席 Mark Nottingham 提出了将 HTTP-over-QUIC 更名为 HTTP/3 的正式请求，以“明确地将其标识为 HTTP 语义的另一个绑定……使人们理解它与 QUIC 的不同”，并在最终确定并发布草案后，将 QUIC 工作组继承到 HTTP 工作组。 在随后的几天讨论中，Mark Nottingham 的提议得到了 IETF 成员的接受，他们在 2018 年 11 月给出了官方批准，认可 HTTP-over-QUIC 成为 HTTP/3。

2019 年 9 月，**HTTP/3 支持已添加到 Cloudflare 和 Google Chrome（Canary build）。Firefox Nightly 在 2019 年秋季之后添加支持**。

2022 年 6 月 6 日，**IETF 正式标准化 HTTP/3 为 RFC9114**。

## QUIC

虽然 QUIC 的名称最初是“`快速 UDP 互联网连接`”（Fast UDP Internet Connection）的首字母缩写，但 IETF 指定的标准中 QUIC 并不是任何内容的缩写。QUIC 提高了目前使用 TCP 的面向连接的网络应用的性能。它通过使用用户数据报协议（UDP）在两个端点之间创建若干个多路连接来实现这一目标，其目的是为了在网络层淘汰 TCP，以满足许多应用的需求，因此该协议偶尔也会获得 “TCP/2”的昵称。

QUIC 与 HTTP/2 的多路复用连接协同工作，允许多个数据流独立到达所有端点，因此不受涉及其他数据流的丢包影响。
相反，HTTP/2 创建在传输控制协议（TCP）上，如果任何一个 TCP 数据包延迟或丢失，所有多路数据流都会遭受队头阻塞延迟。

- QUIC 的`次要目标包括降低连接和传输时延，以及每个方向的带宽估计以避免拥塞`。
- 将拥塞控制算法移到了两个端点的用户空间，而不是内核空间，据称这将使这些算法得到更快的改进。
- 该协议还可以扩展前向纠错（FEC），以进一步提高预期错误时的性能，这被视为协议演进的下一步。

### 介绍

QUIC 旨在提供几乎等同于 TCP 连接的`可靠性`，但延迟大大减少。它主要通过两个理解 HTTP 流量的行为来实现这一点。

**TODO：没懂**

第一个变化是在连接创建期间大大减少开销。由于大多数 HTTP 连接都需要 TLS，因此 QUIC 使协商密钥和支持的协议成为初始握手过程的一部分。 当客户端打开连接时，服务器响应的数据包包括将来的数据包加密所需的数据。这消除了 TCP 上的先连接并通过附加数据包协商安全协议的需要。其他协议可以以相同的方式进行服务，并将多个步骤组合到一个请求中。 然后，这些数据既可用于初始设置中的后续请求，也可用于未来的请求。

**QUIC 流是单独控制的**

`QUIC 使用 UDP 协议作为其基础，不包括丢失恢复。相反，每个 QUIC 流是单独控制的，并且在 QUIC 级别而不是 UDP 级别重传丢失的数据。这意味着如果在一个流中发生错误，协议栈仍然可以独立地继续为其他流提供服务。` 这在提高易出错链路的性能方面非常有用，因为在大多数情况下 TCP 协议通知数据包丢失或损坏之前可能会收到大量的正常数据，但是在纠正错误之前其他的正常请求都会等待甚至重发。 QUIC 在修复单个流时可以自由处理其他数据，也就是说即使一个请求发生了错误也不会影响到其他的请求。

**每个数据包单独加密、单个握手过程**

QUIC 包括许多其他更普通的更改，这些更改也可以`优化整体延迟`和`吞吐量`。例如，`每个数据包是单独加密的，因此加密数据时不需要等待部分数据包`。 在 TCP 下通常不可能这样做，其中加密记录在字节流中，并且协议栈不知道该流中的更高层边界。这些可以由运行在更上层的协议进行协商，但 QUIC 旨在通过**单个握手过程完成**这些。

**提高网络切换期间的性能**

`QUIC 的另一个目标是提高网络切换期间的性能，例如当移动设备的用户从 WiFi 热点切换到移动网络时发生的情况。` 当这发生在 TCP 上时，一个冗长的过程开始了：每个现有连接一个接一个地超时，然后根据需要重新创建。期间存在较高延迟，因为新连接需要等待旧连接超时后才会创建。 为解决此问题，QUIC 包含一个`连接标识符`(是不是 MAC 地址？)，该标识符唯一地标识客户端与服务器之间的连接，而无论源 IP 地址是什么。这样只需发送一个包含此 ID 的数据包即可重新创建连接，因为即使用户的 IP 地址发生变化，原始连接 ID 仍然有效。

**QUIC 在应用程序空间中实现，而不是在操作系统内核中实现，容易扩展**
`QUIC 在应用程序空间中实现，而不是在操作系统内核中实现。当数据在应用程序之间移动时，这通常会由于上下文切换而调用额外的开销。` 但是在 QUIC 下协议栈旨在由单个应用程序使用，每个应用程序使用 QUIC 在 UDP 上托管自己的连接。最终差异可能非常小，因为整个 HTTP/2 堆栈的大部分已经存在于应用程序（或更常见的库）中。 将剩余部分放在这些库中，基本上是纠错，对 HTTP/2 堆栈的大小或整体复杂性几乎没有影响。

QUIC 允许更容易地进行未来更改，因为它不需要更改内核就可以进行更新。 QUIC 的长期目标之一是添加前向纠错和改进的拥塞控制。

关于从 TCP 迁移到 UDP 的一个问题是 TCP 被广泛采用，并且互联网基础设施中的许多中间设备被调整为 UDP 速率限制甚至阻止 UDP。 Google 进行了一些探索性实验来描述这一点，发现只有少数连接存在此问题。所以 Chromium 的网络堆栈同时打开 QUIC 和传统 TCP 连接，并在 QUIC 连接失败时以零延迟回退到 TCP 连接。

### 流量控制

<span style={{color: 'red'}}>注意：流量控制是 QUICK 实现的，UDP 并没有</span>

与大多数传输协议一样，**QUIC 具有流量控制以保护接收端免受缓冲器 overflow 的影响**。QUIC 是基于 UDP 传输，而 UDP 没有流量控制，`因此 QUIC 实现了自己的流量控制机制`。与 TCP 不同，QUIC 并非通过 ACK 回应目前接收到第几笔资料，而是通过 `control frame `实现类似于 HTTP/2 的基于信用的方案。

## HTTP 的发展历史

先后经历了：

1. 万维网的发明
2. HTTP/0.9 - 单行协议
3. HTTP/1.0 - 构建可扩展性
4. HTTP/1.1 - 标准化的协议
5. 超过 15 年的发展（`restful api`、`Server-send events`、`WebSocket`、`跨域资源共享 CORS`、`内容安全策略 CSP`、`隐私控制 DNT`、`X-Frame-Options`）
6. HTTP2 - 为了更优异的表现
7. HTTP3 - 弃用 TCP 协议

<a href="https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Basics_of_HTTP/Evolution_of_HTTP" target="_blank" >见</a>

## X-Frame-Options

X-Frame-Options `HTTP 响应头是用来给浏览器指示允许一个页面可否在` `<frame> `、`<iframe>`、`<embed>` 或者 `<object>` 中展现的标记。站点可以通过确保网站没有被嵌入到别人的站点里面，从而避免点击劫持攻击。

1. X-Frame-Options: `DENY`
2. X-Frame-Options: `SAMEORIGIN`

<a href="https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/X-Frame-Options" target="_blank" >见</a>

## 参考链接

<a href="https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Connection_management_in_HTTP_1.x" target="_blank" >MDN HTTP 连接管理</a>

<a href="https://zh.wikipedia.org/wiki/QUIC" target="_blank" >维基百科 QUIC</a>

<a href="https://zh.wikipedia.org/wiki/HTTP/3" target="_blank" >维基百科 HTTP/3</a>
